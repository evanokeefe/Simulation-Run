{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import csv\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input,Dense, Conv3D, Flatten, MaxPooling3D, BatchNormalization, GlobalAveragePooling3D, LeakyReLU, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for loading data\n",
    "#loading microstructure \n",
    "def load_X1data(number=100,dim=100):\n",
    "    X1data=np.empty((number,dim,dim,dim,1))\n",
    "    X1data_temp=np.empty((dim,dim,dim,1))\n",
    "    for n in range(0,number):\n",
    "        structure_path='structure/struct_{:03d}.in'.format(n)\n",
    "        structure=np.loadtxt(structure_path)\n",
    "        \n",
    "        for i in range(0,dim):\n",
    "            for j in range(0,dim):\n",
    "                for k in range(0,dim):\n",
    "                    X1data_temp[i,j,k,0]=structure[k+j*dim+i*dim*dim,3]\n",
    "        \n",
    "        X1data[n,]=X1data_temp[:]\n",
    "        \n",
    "    return X1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading interface conductivity    \n",
    "def load_X2data(number=100):\n",
    "    X2data=np.empty((number,1))\n",
    "    with open('interface_conductivity.csv') as csv_file:\n",
    "        X2data_file=csv.reader(csv_file)\n",
    "        for i,sample in enumerate(X2data_file):\n",
    "            X2data[i,0]=np.asarray(sample[:],dtype=np.float64)\n",
    "\n",
    "    return X2data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading conductivity\n",
    "def load_Ydata(number=100):\n",
    "    Ydata=np.empty((number,1))\n",
    "    with open('conductivity.csv') as csv_file:\n",
    "        Ydata_file=csv.reader(csv_file)\n",
    "        for i,sample in enumerate(Ydata_file):\n",
    "            Ydata[i,0]=np.asarray(sample[:],dtype=np.float64)\n",
    "\n",
    "    return Ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify data dimension\n",
    "dim=100   #dim of structure\n",
    "\n",
    "#CNN model set\n",
    "X1data_input=Input(shape=(dim,dim,dim,1))  #input1 shape\n",
    "X2data_input=Input(shape=(1,))  #input2 shape\n",
    "\n",
    "conv1=Conv3D(64, (3,3,3), activation='relu',data_format='channels_last')(X1data_input) # first CNN layer\n",
    "#conv1=BatchNormalization()(conv1)\n",
    "conv2=Conv3D(32, (3,3,3), activation='relu',kernel_regularizer=l2(0.01),activity_regularizer=l2(0.01))(conv1)# second CNN layer\n",
    "#conv2=BatchNormalization()(conv2)\n",
    "pooling1=MaxPooling3D(pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None)(conv2) # maxPooling\n",
    "conv3=Conv3D(16, (3,3,3), activation='relu',kernel_regularizer=l2(0.01),activity_regularizer=l2(0.01))(pooling1)\n",
    "#conv3=BatchNormalization()(conv3)\n",
    "pooling2=MaxPooling3D(pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None)(conv3)\n",
    "\n",
    "flatten=Flatten()(pooling2)  #flatten\n",
    "#flatten=BatchNormalization()(flatten)\n",
    "Dropout1=Dropout(rate=0.5)(flatten)\n",
    "Dense1=Dense(256,activation=\"relu\",kernel_regularizer=l2(0.01),activity_regularizer=l2(0.01))(Dropout1)\n",
    "#Dense1=BatchNormalization()(Dense1)\n",
    "Dropout2=Dropout(rate=0.5)(Dense1)\n",
    "featuremap=Dense(16, activation= \"relu\")(Dropout2) # fully connected layer, output probablities\n",
    "merged=keras.layers.concatenate([featuremap,X2data_input])  #add interface conductivity to feature map\n",
    "result=Dense(1)(merged)  #final result\n",
    "my_model=Model(inputs=[X1data_input,X2data_input],outputs=result) #specify input and output of the model\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "my_model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mse']) #compile the model\n",
    "\n",
    "#print summayr of the model\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "#load data\n",
    "number=667   #number of data points\n",
    "X1data=load_X1data(number,dim)   #size of X1data: (number,dim,dim,dim,1)\n",
    "X2data=load_X2data(number)     #size of X2data: (number,1)\n",
    "Ydata=load_Ydata(number)      #size of Ydata: (number,1)\n",
    "\n",
    "#Specify training and testing set  \n",
    "X1data_train=X1data[:-60]\n",
    "X2data_train=X2data[:-60]\n",
    "Ydata_train=Ydata[:-60]\n",
    "X1data_test=X1data[-60:]\n",
    "X2data_test=X2data[-60:]\n",
    "Ydata_test=Ydata[-60:]\n",
    "\n",
    "#main\n",
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto',period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#check input and output data shape\n",
    "print(X1data_train.shape)\n",
    "print(X2data_train.shape)\n",
    "print(Ydata_train.shape)\n",
    "\n",
    "#model fit\n",
    "my_model.fit([X1data_train,X2data_train],Ydata_train, epochs=500, batch_size=32, validation_split = 0.1, callbacks=callbacks_list)\n",
    "\n",
    "#\n",
    "## Load wights file of the best model :\n",
    "#wights_file = checkpoint_name # choose the best checkpoint \n",
    "#my_model.load_weights(wights_file) # load it\n",
    "#my_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}